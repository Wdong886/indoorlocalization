# Import required libraries
import torch
import numpy as np
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import NearestNeighbors
from featureExtraction import main as extract_features  # Import the feature extraction function
import matplotlib.pyplot as plt
import json

# Define paths to the images
image1_path = "data/Query_image/test.jpg"  # Query image
image2_path = "temp/projected_image_fixed.png"  # Image generated by point cloud clusters

# Define timesteps for feature extraction
timesteps = [0, 2, 4, 6]  # Define desired timesteps

# Step 1: Extract features for each image
features_image1 = extract_features(image1_path, timesteps)
features_image2 = extract_features(image2_path, timesteps)


# Step 2: Concatenate features along the channel dimension
def concatenate_features(features):
    """Concatenate list of feature maps along the channel dimension."""
    concatenated = torch.cat([f.view(-1) for f in features], dim=0)  # Flatten and concatenate along channels
    return concatenated.cpu().numpy()  # Convert to numpy array for further processing


# Concatenate features for each image
concatenated_features_image1 = concatenate_features(features_image1)
concatenated_features_image2 = concatenate_features(features_image2)

# Step 3: Standardize features using Z-score normalization
scaler = StandardScaler()
standardized_features_image1 = scaler.fit_transform(concatenated_features_image1.reshape(1, -1))
standardized_features_image2 = scaler.transform(concatenated_features_image2.reshape(1, -1))

# Step 4: Apply PCA to reduce dimensionality
pca = PCA(n_components=50)  # Set the number of components based on the desired dimensionality
reduced_features_image1 = pca.fit_transform(standardized_features_image1)
reduced_features_image2 = pca.transform(standardized_features_image2)

# Step 5: Use nearest neighbor matching for image feature comparison
# Combine features into a dataset for nearest neighbor matching
feature_dataset = np.vstack((reduced_features_image1, reduced_features_image2))

# Initialize Nearest Neighbors model with a controlled number of matches
num_matches = 5  # Set the desired number of matching points
nbrs = NearestNeighbors(n_neighbors=num_matches, algorithm='auto').fit(feature_dataset)

# Find nearest neighbors
distances, indices = nbrs.kneighbors(feature_dataset)

# Load pixel-to-point map from text file
with open(r'temp/pixel_to_point_map.txt', 'r') as f:
    pixel_to_point_map = {}
    for line in f:
        # Parse each line in the format "Pixel (u, v): Point [x, y, z]"
        parts = line.strip().split(": ")
        pixel_str = parts[0].split("(")[1].split(")")[0]
        point_str = parts[1].split("[")[1].split("]")[0]

        # Extract pixel and point coordinates
        u, v = map(int, pixel_str.split(", "))
        x, y, z = map(float, point_str.split(", "))

        # Store in the dictionary
        pixel_to_point_map[(u, v)] = [x, y, z]

# Step 6: Retrieve and map matching points from image1 and corresponding point cloud coordinates for image2
matches_image1 = []  # To store matching coordinates in image1
matches_image2 = []  # To store matching coordinates in image2

for i in range(1, num_matches + 1):  # Start from 1 to skip self-match
    # Get coordinates in image1 and image2
    image1_coords = indices[0][i]  # Index in image1
    image2_coords = indices[1][i]  # Index in image2

    matches_image1.append(image1_coords)
    matches_image2.append(image2_coords)

# Map each pixel in image2 to its point cloud coordinates using the pixel_to_point_map
matched_point_cloud_coords = []
for u, v in matches_image2:
    if (u, v) in pixel_to_point_map:
        matched_point_cloud_coords.append(pixel_to_point_map[(u, v)])
    else:
        matched_point_cloud_coords.append(None)  # Mark as None if no mapping is found

# Step 7: Save matching points to a txt file with specified format
output_file = r'temp/pixel_to_point_map.txt'
with open(output_file, 'w') as f:
    for idx, (img1_coords, img2_coords) in enumerate(zip(matches_image1, matches_image2)):
        img1_str = f"Image1 pixel coordinates: {img1_coords}"
        img2_str = f"Image2 pixel coordinates: {img2_coords}"
        point_cloud_str = f"Point cloud coordinates: {matched_point_cloud_coords[idx]}" if matched_point_cloud_coords[
            idx] else "No match in point cloud"

        # Write to file
        f.write(f"{img1_str}, {img2_str}, {point_cloud_str}\n")

        # Print for verification
        print(f"{img1_str}, {img2_str}, {point_cloud_str}")

print(f"Matching points have been saved to {output_file}")
